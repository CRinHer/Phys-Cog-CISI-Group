{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "084b293d",
      "metadata": {
        "id": "084b293d"
      },
      "source": [
        "This notebook will contain the results of each tutorial from the NeuralMI webpage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6fa95da6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fa95da6",
        "outputId": "eb91bb4f-00d9-4d21-c433-248bdf2e2fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/eslam-abdelaleem/NeuralMI.git\n",
            "  Cloning https://github.com/eslam-abdelaleem/NeuralMI.git to /tmp/pip-req-build-1jcljyo5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/eslam-abdelaleem/NeuralMI.git /tmp/pip-req-build-1jcljyo5\n",
            "  Resolved https://github.com/eslam-abdelaleem/NeuralMI.git to commit 8cabb315bf69b31dc7e32f82c291afe1cef13135\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (2.2.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (0.14.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from neural_mi==1.0.0) (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neural_mi==1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->neural_mi==1.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->neural_mi==1.0.0) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->neural_mi==1.0.0) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->neural_mi==1.0.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->neural_mi==1.0.0) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->neural_mi==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->neural_mi==1.0.0) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->neural_mi==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->neural_mi==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->neural_mi==1.0.0) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/eslam-abdelaleem/NeuralMI.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 1: A First MI Estimate"
      ],
      "metadata": {
        "id": "-aXOzAiHZnWL"
      },
      "id": "-aXOzAiHZnWL"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import neural_mi as nmi\n",
        "\n",
        "# --- Dataset Parameters ---\n",
        "n_samples = 5000\n",
        "dim = 5\n",
        "ground_truth_mi_bits = 2.0\n",
        "\n",
        "# --- Generate Raw 2D Data ---\n",
        "# This creates data of shape (n_samples, dim).\n",
        "x_raw, y_raw = nmi.datasets.generate_correlated_gaussians(\n",
        "    n_samples=n_samples,\n",
        "    dim=dim,\n",
        "    mi=ground_truth_mi_bits\n",
        ")\n",
        "\n",
        "# Transpose to the expected (n_channels, n_timepoints) format for the processor\n",
        "x_raw_transposed = x_raw.T\n",
        "y_raw_transposed = y_raw.T\n",
        "\n",
        "print(f\"Transposed X data shape: {x_raw_transposed.shape}\")\n",
        "print(f\"Transposed Y data shape: {y_raw_transposed.shape}\")\n",
        "\n",
        "# The processor will treat each of the 5000 columns as an independent sample.\n",
        "processor_params = {'window_size': 1}\n",
        "\n",
        "# Basic model and training parameters\n",
        "base_params = {\n",
        "    'n_epochs': 50, 'learning_rate': 5e-4, 'batch_size': 128,\n",
        "    'patience': 10, 'embedding_dim': 16, 'hidden_dim': 64, 'n_layers': 2\n",
        "}\n",
        "\n",
        "results = nmi.run(\n",
        "    x_data=x_raw_transposed, y_data=y_raw_transposed,\n",
        "    mode='estimate',\n",
        "    processor_type='continuous',\n",
        "    processor_params=processor_params,\n",
        "    base_params=base_params,\n",
        "    output_units='bits', # Specify the output units\n",
        "    random_seed=42       # For reproducibility\n",
        ")\n",
        "\n",
        "estimated_mi_bits = results.mi_estimate\n",
        "\n",
        "print(f\"\\n--- Results ---\")\n",
        "print(f\"Ground Truth MI:  {ground_truth_mi_bits:.3f} bits\")\n",
        "print(f\"Estimated MI:     {estimated_mi_bits:.3f} bits\")\n",
        "print(f\"Estimation Error: {abs(estimated_mi_bits - ground_truth_mi_bits):.3f} bits\")"
      ],
      "metadata": {
        "id": "jmij1xRpB3zY"
      },
      "id": "jmij1xRpB3zY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 2: A Visual Guide to Neuroscience Data Processing"
      ],
      "metadata": {
        "id": "yHh2IBT8ZwV0"
      },
      "id": "yHh2IBT8ZwV0"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import neural_mi as nmi\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "raw_continuous_data = np.sin(np.linspace(0, 10, 100)).reshape(1, 100)\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(raw_continuous_data.T, marker='.')\n",
        "plt.title(\"Before: Raw Continuous Signal\")\n",
        "plt.xlabel(\"Timepoint\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True, linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Raw data shape: {raw_continuous_data.shape}\")\n",
        "\n",
        "window_size = 10\n",
        "sample_idx_to_show = 5\n",
        "start = sample_idx_to_show\n",
        "end = start + window_size\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(raw_continuous_data.T, color='gray', marker='.')\n",
        "plt.plot(np.arange(start, end), raw_continuous_data.T[start:end], color='red', marker='o')\n",
        "plt.axvspan(start, end - 1, color='red', alpha=0.2, label=f'Data for Sample #{sample_idx_to_show}')\n",
        "plt.title(\"During: The Sliding Window in Action\")\n",
        "plt.xlabel(\"Timepoint\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "processor = nmi.data.ContinuousProcessor(window_size=window_size, step_size=1)\n",
        "processed_data = processor.process(raw_continuous_data)\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(processed_data[sample_idx_to_show, 0, :].numpy(), 'o-', color='red')\n",
        "plt.title(f\"After: Contents of Processed Sample #{sample_idx_to_show}\")\n",
        "plt.xlabel(\"Timepoint within Window\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.grid(True, linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Processed data shape: {processed_data.shape}\")\n",
        "\n",
        "spike_data, _ = nmi.datasets.generate_correlated_spike_trains(\n",
        "    n_neurons=5,\n",
        "    duration=2.0, # Use a shorter duration for visualization\n",
        "    firing_rate=15\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.eventplot(spike_data, color='black')\n",
        "plt.title(\"Before: Raw Spike Data (Raster Plot)\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Neuron ID\")\n",
        "plt.grid(True, linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "window_size_s = 0.1 # 100 ms\n",
        "step_size_s = 0.01  # 10 ms\n",
        "sample_idx_to_show = 50\n",
        "\n",
        "start_time = sample_idx_to_show * step_size_s\n",
        "end_time = start_time + window_size_s\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.eventplot(spike_data, color='black')\n",
        "plt.axvspan(start_time, end_time, color='red', alpha=0.2, label=f'Data for Sample #{sample_idx_to_show}')\n",
        "plt.title(\"During: Windowing the Spike Raster\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Neuron ID\")\n",
        "plt.xlim(start_time - window_size_s*2, end_time + window_size_s*2)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "max_spikes = nmi.data.processors.find_max_spikes_per_window(spike_data, window_size_s)\n",
        "spike_processor = nmi.data.SpikeProcessor(\n",
        "    window_size=window_size_s, step_size=step_size_s, max_spikes_per_window=max_spikes\n",
        ")\n",
        "processed_spike_data = spike_processor.process(spike_data)\n",
        "\n",
        "print(f\"After: Contents of Processed Sample #{sample_idx_to_show}\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(f\"Window Time: [{start_time:.2f}s, {end_time:.2f}s]\")\n",
        "print(f\"Processed Tensor Shape: {processed_spike_data.shape}\")\n",
        "print(\"\\nContents (Spike times relative to window start):\")\n",
        "for i in range(len(spike_data)):\n",
        "    content = processed_spike_data[sample_idx_to_show, i, :].numpy()\n",
        "    print(f\"  Neuron {i}: {np.round(content, 3)}\")\n",
        "\n",
        "raw_cat_data, _ = nmi.datasets.generate_correlated_categorical_series(\n",
        "    n_samples=50, n_channels=1, n_categories=3, use_torch=False\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 1.5))\n",
        "ax.imshow(raw_cat_data, aspect='auto', cmap='viridis', interpolation='nearest')\n",
        "ax.set_title(\"Before: Raw Categorical States\")\n",
        "ax.set_xlabel(\"Timepoint\")\n",
        "ax.set_ylabel(\"Channel\")\n",
        "ax.set_yticks([])\n",
        "plt.show()\n",
        "print(f\"Raw data: {raw_cat_data[0, :20]}...\")\n",
        "\n",
        "cat_processor = nmi.data.CategoricalProcessor(window_size=3, step_size=1)\n",
        "processed_cat_data = cat_processor.process(raw_cat_data)\n",
        "\n",
        "first_window_raw = raw_cat_data[0, :3]\n",
        "first_window_processed = processed_cat_data[0, 0, :]\n",
        "\n",
        "print(f\"Raw states for first window: {first_window_raw}\")\n",
        "print(f\"Processed one-hot vector:    {first_window_processed.numpy()}\")\n",
        "print(f\"\\nFinal processed shape: {processed_cat_data.shape}\")\n",
        "\n",
        "# Visualize the one-hot encoding\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 2), gridspec_kw={'width_ratios': [1, 3]})\n",
        "ax1.imshow(first_window_raw.reshape(1, -1), cmap='viridis', aspect='auto', vmin=0, vmax=2)\n",
        "ax1.set_title(\"During: Raw Window\")\n",
        "ax1.set_yticks([])\n",
        "\n",
        "ax2.imshow(first_window_processed.reshape(3, 3), cmap='gray_r', aspect='auto')\n",
        "ax2.set_title(\"After: One-Hot Encoded & Flattened Vector\")\n",
        "ax2.set_yticks([])\n",
        "plt.show()\n",
        "\n",
        "x_cont_raw = np.random.randn(2, 1000)\n",
        "y_spike_raw, _ = nmi.datasets.generate_correlated_spike_trains(n_neurons=5, duration=10.0)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
        "ax1.plot(np.linspace(0, 10, 1000), x_cont_raw.T)\n",
        "ax1.set_title(\"Before: Raw Continuous Data (X)\")\n",
        "ax1.set_ylabel(\"Amplitude\")\n",
        "ax1.grid(True, linestyle=':')\n",
        "\n",
        "ax2.eventplot(y_spike_raw, color='black')\n",
        "ax2.set_title(\"Before: Raw Spike Data (Y)\")\n",
        "ax2.set_xlabel(\"Time (s)\")\n",
        "ax2.set_ylabel(\"Neuron ID\")\n",
        "ax2.grid(True, linestyle=':')\n",
        "plt.show()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
        "ax1.plot(np.linspace(0, 10, 1000), x_cont_raw.T)\n",
        "ax1.set_title(\"Before: Raw Continuous Data (X)\")\n",
        "ax1.set_ylabel(\"Amplitude\")\n",
        "ax1.grid(True, linestyle=':')\n",
        "\n",
        "ax2.eventplot(y_spike_raw, color='black')\n",
        "ax2.set_title(\"Before: Raw Spike Data (Y)\")\n",
        "ax2.set_xlabel(\"Time (s)\")\n",
        "ax2.set_ylabel(\"Neuron ID\")\n",
        "ax2.grid(True, linestyle=':')\n",
        "ax2.set_xlim(0,0.5)\n",
        "plt.show()\n",
        "\n",
        "handler = nmi.data.DataHandler(\n",
        "    x_data=x_cont_raw, y_data=y_spike_raw,\n",
        "    processor_type_x='continuous', processor_params_x={'window_size': 100, 'step_size': 10}, # -> 91 samples\n",
        "    processor_type_y='spike', processor_params_y={'window_size': 0.5, 'step_size': 0.05}     # -> 191 samples\n",
        ")\n",
        "\n",
        "x_processed, y_processed = handler.process()\n",
        "\n",
        "print(\"--- Theoretical vs. Actual Sample Counts ---\")\n",
        "print(\"Continuous theoretical samples: 91\")\n",
        "print(\"Spike theoretical samples: 191\")\n",
        "print(\"The library will align to the smaller count.\\n\")\n",
        "print(\"--- Final Processed Shapes ---\")\n",
        "print(f\"X (Continuous) shape: {x_processed.shape}\")\n",
        "print(f\"Y (Spike) shape:      {y_processed.shape}\")\n",
        "print(\"\\nThe number of samples (dim 0) is now identical!\")\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
        "ax1.plot(np.linspace(0, 0.5, 100), x_processed[0,:,:].T)\n",
        "ax1.set_title(\"After: 1st Window of Continuous Data (X)\")\n",
        "ax1.set_ylabel(\"Amplitude\")\n",
        "ax1.grid(True, linestyle=':')\n",
        "\n",
        "ax2.eventplot(y_processed[0,:,:], color='black')\n",
        "ax2.set_title(\"After: 1st Window of Spike Data (Y)\")\n",
        "ax2.set_xlabel(\"Time (s)\")\n",
        "ax2.set_ylabel(\"Neuron ID\")\n",
        "ax2.grid(True, linestyle=':')\n",
        "ax2.set_xlim(left=0.001)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L_EmMXQaCQVX"
      },
      "id": "L_EmMXQaCQVX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 3 (Finding Temporal Relationships)"
      ],
      "metadata": {
        "id": "a_qofen7DEyu"
      },
      "id": "a_qofen7DEyu"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import neural_mi as nmi\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_context(\"talk\")"
      ],
      "metadata": {
        "id": "46BbWXj8DEHb"
      },
      "id": "46BbWXj8DEHb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_lag = 30\n",
        "x_raw, y_raw = nmi.datasets.generate_temporally_convolved_data(\n",
        "    n_samples=10000, lag=ground_truth_lag, noise=0.1\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(x_raw[0, :200], label='X')\n",
        "plt.plot(y_raw[0, :200], label=f'Y (lagged by {ground_truth_lag} steps)', alpha = 0.8)\n",
        "plt.title(\"A Simple Lagged Relationship\")\n",
        "plt.xlabel(\"Timepoint\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=':')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xWQlhGR_D7ed"
      },
      "id": "xWQlhGR_D7ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_params = {\n",
        "    'n_epochs': 50, 'learning_rate': 1e-3, 'batch_size': 64,\n",
        "    'patience': 20, 'embedding_dim': 16, 'hidden_dim': 128, 'n_layers': 2,\n",
        "    'embedding_model': 'cnn',       # Use a CNN for temporal data\n",
        "    # 'critic_type': 'bilinear'     # Use a powerful critic for a clear result\n",
        "}\n",
        "\n",
        "sweep_grid = {'window_size': [1, 10, 20, 30, 40, 60, 100],\n",
        "             'run_id': range(5)}\n",
        "\n",
        "window_results = nmi.run(\n",
        "    x_data=x_raw, y_data=y_raw, mode='sweep',\n",
        "    processor_type_x='continuous', processor_params_x={},\n",
        "    base_params=base_params,\n",
        "    sweep_grid=sweep_grid,\n",
        "    n_workers=2,\n",
        "    random_seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "4ZLpu0-5EzaH"
      },
      "id": "4ZLpu0-5EzaH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = window_results.plot(show=False)\n",
        "ax.axvline(x=ground_truth_lag, color='red', linestyle='--', label=f'True Lag({ground_truth_lag})')\n",
        "ax.set_title(\"Finding Interaction Duration with a Window Sweep\")\n",
        "ax.set_xlabel(\"Window Size\")\n",
        "ax.legend()\n",
        "ax.set_ylim(bottom=0)\n",
        "plt.show()\n",
        "\n",
        "best_run = window_results.dataframe.loc[window_results.dataframe['mi_mean'].idxmax()]\n",
        "print(f\"--- Best Result ---\\nOptimal Window Size: {best_run['window_size']}\")"
      ],
      "metadata": {
        "id": "wZOWbv44HJCz"
      },
      "id": "wZOWbv44HJCz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For lag analysis, we need to fix the window size.\n",
        "# We'll use the optimal one we just found.\n",
        "processor_params = {'window_size': 40}\n",
        "\n",
        "# We'll test a range of lags from -50 to +50.\n",
        "lag_range = range(-50, 51, 10)\n",
        "\n",
        "lag_results = nmi.run(\n",
        "    x_data=x_raw,\n",
        "    y_data=y_raw,\n",
        "    mode='lag',\n",
        "    processor_type_x='continuous',\n",
        "    processor_params_x=processor_params,\n",
        "    base_params=base_params,\n",
        "    lag_range=lag_range,\n",
        "    n_workers=2,\n",
        "    random_seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "oVE9O17oJoE_"
      },
      "id": "oVE9O17oJoE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = lag_results.plot(show=False)\n",
        "ax.axvline(x=ground_truth_lag, color='red', linestyle='--', label=f'True Lag({ground_truth_lag})')\n",
        "ax.set_title(\"Finding the Precise Offset with a Lag Analysis\")\n",
        "ax.set_xlabel(\"Lag (Timepoints)\")\n",
        "ax.legend()\n",
        "ax.set_ylim(bottom=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mUYtddZAKbCx"
      },
      "id": "mUYtddZAKbCx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 4: Choosing the Right Model and Estimator"
      ],
      "metadata": {
        "id": "eVwEGHIvW1GV"
      },
      "id": "eVwEGHIvW1GV"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import neural_mi as nmi\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.nn import Sequential, Linear, Softplus\n",
        "from torch.cuda.amp import autocast\n",
        "import gc\n",
        "import os\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "sns.set_context(\"talk\")"
      ],
      "metadata": {
        "id": "_Y6Uckh7W43o"
      },
      "id": "_Y6Uckh7W43o",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the shared latent variable Z\n",
        "n_samples = 5000\n",
        "z = torch.randn(n_samples, 2)\n",
        "\n",
        "# 2. Create a 45-degree rotation matrix for Y's latent variable\n",
        "angle = np.pi/4\n",
        "rotation_matrix = torch.tensor([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]], dtype=torch.float32)\n",
        "z_rotated = z @ rotation_matrix\n",
        "\n",
        "# 3. Create nonlinear mappings from latent to a high-dimensional observed space\n",
        "mlp = Sequential(Linear(2,64), Softplus(), Linear(64, 50))\n",
        "x_raw = mlp(z).T.detach()\n",
        "y_raw = mlp(z_rotated).T.detach()"
      ],
      "metadata": {
        "id": "lxu_zz6T1Rf5"
      },
      "id": "lxu_zz6T1Rf5",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we sweep over the critic types to see which one can solve the task\n",
        "sweep_grid_separable_bilinear = {\n",
        "    'critic_type': ['separable', 'bilinear'],\n",
        "    # 'critic_type': ['concat'],\n",
        "    'run_id': range(5) # Average over 5 runs for stability\n",
        "}\n",
        "\n",
        "base_params = {\n",
        "    'n_epochs': 100, 'learning_rate': 5e-4, 'batch_size': 64,\n",
        "    'patience': 20, 'embedding_dim':8, 'hidden_dim': 64, 'n_layers': 3\n",
        "}\n",
        "\n",
        "critic_results_separable_bilinear = nmi.run(\n",
        "    x_data=x_raw, y_data=y_raw,\n",
        "    mode='sweep',\n",
        "    processor_type_x='continuous',\n",
        "    processor_params_x={'window_size': 1},\n",
        "    base_params=base_params,\n",
        "    sweep_grid=sweep_grid_separable_bilinear,\n",
        "    n_workers=1,\n",
        "    random_seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "d4w8PH9S2Rk3"
      },
      "id": "d4w8PH9S2Rk3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=critic_results_separable_bilinear.dataframe, x='critic_type', y='mi_mean', capsize=0.1, order=['separable', 'bilinear', 'concat'])\n",
        "plt.title('Critic Performance on the Rotated Manifold Task')\n",
        "plt.ylabel('Estimated MI (bits)')\n",
        "plt.xlabel('Critic Architecture')\n",
        "plt.ylim(bottom=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ui1OiZxi3t22"
      },
      "id": "Ui1OiZxi3t22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to get concat critic to not crash when I try running it\n",
        "sweep_grid_concat = {\n",
        "    'critic_type': ['concat'],\n",
        "    'run_id': range(5) # Average over 5 runs for stability\n",
        "}\n",
        "\n",
        "base_params = {\n",
        "    'n_epochs': 100, 'learning_rate': 5e-4, 'batch_size': 64,\n",
        "    'patience': 20, 'embedding_dim':8, 'hidden_dim': 64, 'n_layers': 3\n",
        "}\n",
        "\n",
        "x_raw = x_raw.half()\n",
        "y_raw = y_raw.half()\n",
        "\n",
        "outputs = []\n",
        "for i in range(0, len(x_raw), 128):\n",
        "  out = nmi.run(\n",
        "      x_data=x_raw[i:i+128], y_data=y_raw[i:i+128],\n",
        "      mode='sweep',\n",
        "      processor_type_x='continuous',\n",
        "      processor_params_x={'window_size': 1},\n",
        "      base_params=base_params,\n",
        "      sweep_grid=sweep_grid_concat,\n",
        "      n_workers=1,\n",
        "      random_seed=42\n",
        "  )\n",
        "  outputs.append(out)"
      ],
      "metadata": {
        "id": "xRZY4RY8ZiWm",
        "outputId": "2a046a19-53ef-4738-df2f-999bb2734c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "c9cf1de5f9a040309b02d6d95dadf5d3",
            "06cf43a1e7ee48918515f96294e2e76c",
            "fee55134873a44c38beef5709d2cb764",
            "c975045ab35441eaae540115b51ef9fe",
            "61dfc51c7ace496399bcc94a85345034",
            "7922e143629f4c55a2c44d684b87af12",
            "28d5c39511184212b8477b44fb9da701",
            "d1462cbd7ab8479b9faafe6b9e893c62",
            "571e00f699974944b8ee87cfbe222400",
            "fa79e846862c43edae94e6571f1ec0a2",
            "9c701854bdeb4fe99cfc91c34ff89993",
            "0ef24e77f0af4d83819cbae90e2cb599",
            "6367730fd0f24a5791577195dc967fb2",
            "b242c793c5004bf0aabded00ea4bbfcc",
            "df46e298a3f6421dbcf27c5d2113f598",
            "f883762ceabd4439b4a4f339ffa95092",
            "ee073c348ef64c5093e4f8e6a2f6c180",
            "57f0e502149946369ebe56a56f92b9c4",
            "63347a7297eb457cb7d186920f28b415",
            "24d597b6d2764e4ebec8946f0bcf7294",
            "635d6ced2b0747709c22c9711f528a44",
            "e5f8a3b092d041dda6a1efce4a54f711"
          ]
        }
      },
      "id": "xRZY4RY8ZiWm",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-15 01:23:57 - neural_mi - INFO - Starting parameter sweep sequentially (n_workers=1)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:neural_mi:Starting parameter sweep sequentially (n_workers=1)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sequential Sweep Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9cf1de5f9a040309b02d6d95dadf5d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Run 5d2b0054-8037-47f5-aaac-c64edc41dba7_c0:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ef24e77f0af4d83819cbae90e2cb599"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 14.74 GiB of which 3.25 GiB is free. Process 91605 has 11.49 GiB memory in use. Of the allocated memory 11.34 GiB is allocated by PyTorch, and 13.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-586441683.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   out = nmi.run(\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mx_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sweep'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neural_mi/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(x_data, y_data, mode, processor_type, processor_params, processor_type_x, processor_params_x, processor_type_y, processor_params_y, base_params, sweep_grid, output_units, estimator, estimator_params, custom_critic, custom_embedding_cls, save_best_model_path, random_seed, verbose, device, delta_threshold, min_gamma_points, confidence_level, **analysis_kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameterSweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sweep'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         results_list = ParameterSweep(x_run_data, y_run_data, base_params).run(\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0msweep_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_proc_sweep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_proc_sweep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0manalysis_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neural_mi/analysis/sweep.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sweep_grid, is_proc_sweep, n_workers, max_samples_per_task)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting parameter sweep sequentially (n_workers=1)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrun_training_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Sequential Sweep Progress\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting parameter sweep with {n_workers} workers...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neural_mi/analysis/task.py\u001b[0m in \u001b[0;36mrun_training_task\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     63\u001b[0m                       estimator_params=params.get('estimator_params'))\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     results = trainer.train(x_data, y_data, params['n_epochs'], params['batch_size'],\n\u001b[0m\u001b[1;32m     66\u001b[0m                               \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patience'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                               \u001b[0moutput_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_units'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neural_mi/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_data, y_data, n_epochs, batch_size, train_fraction, n_test_blocks, patience, smoothing_sigma, median_window, min_improvement, save_best_model_path, run_id, output_units, verbose)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mtrain_mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mtest_mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neural_mi/training/trainer.py\u001b[0m in \u001b[0;36m_eval_mi\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neural_mi/models/critics.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mx_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mx_tiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0my_tiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mxy_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tiled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 14.74 GiB of which 3.25 GiB is free. Process 91605 has 11.49 GiB memory in use. Of the allocated memory 11.34 GiB is allocated by PyTorch, and 13.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_mi = 8.0\n",
        "batch_size = 128\n",
        "infonce_limit_bits = np.log(batch_size) / np.log(2)\n",
        "\n",
        "x_high_mi, y_high_mi = nmi.datasets.generate_correlated_gaussians(\n",
        "    n_samples=10000, dim=20, mi=ground_truth_mi\n",
        ")\n",
        "\n",
        "# Use a powerful model to ensure the estimator is the limiting factor\n",
        "high_mi_params = {\n",
        "    'n_epochs': 100, 'learning_rate': 5e-4, 'batch_size': batch_size,\n",
        "    'patience': 20, 'embedding_dim': 32, 'hidden_dim': 128, 'n_layers': 3\n",
        "}\n",
        "\n",
        "print(\"--- Running with InfoNCE (default) ---\")\n",
        "infonce_results = nmi.run(\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "TLiUYIZb4Uqh"
      },
      "id": "TLiUYIZb4Uqh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9cf1de5f9a040309b02d6d95dadf5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06cf43a1e7ee48918515f96294e2e76c",
              "IPY_MODEL_fee55134873a44c38beef5709d2cb764",
              "IPY_MODEL_c975045ab35441eaae540115b51ef9fe"
            ],
            "layout": "IPY_MODEL_61dfc51c7ace496399bcc94a85345034"
          }
        },
        "06cf43a1e7ee48918515f96294e2e76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7922e143629f4c55a2c44d684b87af12",
            "placeholder": "",
            "style": "IPY_MODEL_28d5c39511184212b8477b44fb9da701",
            "value": "SequentialSweepProgress:0%"
          }
        },
        "fee55134873a44c38beef5709d2cb764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1462cbd7ab8479b9faafe6b9e893c62",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_571e00f699974944b8ee87cfbe222400",
            "value": 0
          }
        },
        "c975045ab35441eaae540115b51ef9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa79e846862c43edae94e6571f1ec0a2",
            "placeholder": "",
            "style": "IPY_MODEL_9c701854bdeb4fe99cfc91c34ff89993",
            "value": "0/5[00:12&lt;?,?it/s]"
          }
        },
        "61dfc51c7ace496399bcc94a85345034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7922e143629f4c55a2c44d684b87af12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d5c39511184212b8477b44fb9da701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1462cbd7ab8479b9faafe6b9e893c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571e00f699974944b8ee87cfbe222400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa79e846862c43edae94e6571f1ec0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c701854bdeb4fe99cfc91c34ff89993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ef24e77f0af4d83819cbae90e2cb599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6367730fd0f24a5791577195dc967fb2",
              "IPY_MODEL_b242c793c5004bf0aabded00ea4bbfcc",
              "IPY_MODEL_df46e298a3f6421dbcf27c5d2113f598"
            ],
            "layout": "IPY_MODEL_f883762ceabd4439b4a4f339ffa95092"
          }
        },
        "6367730fd0f24a5791577195dc967fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee073c348ef64c5093e4f8e6a2f6c180",
            "placeholder": "",
            "style": "IPY_MODEL_57f0e502149946369ebe56a56f92b9c4",
            "value": "Run5d2b0054-8037-47f5-aaac-c64edc41dba7_c0|MI:8.809:59%"
          }
        },
        "b242c793c5004bf0aabded00ea4bbfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63347a7297eb457cb7d186920f28b415",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24d597b6d2764e4ebec8946f0bcf7294",
            "value": 59
          }
        },
        "df46e298a3f6421dbcf27c5d2113f598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_635d6ced2b0747709c22c9711f528a44",
            "placeholder": "",
            "style": "IPY_MODEL_e5f8a3b092d041dda6a1efce4a54f711",
            "value": "59/100[00:12&lt;00:08,4.98it/s]"
          }
        },
        "f883762ceabd4439b4a4f339ffa95092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee073c348ef64c5093e4f8e6a2f6c180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f0e502149946369ebe56a56f92b9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63347a7297eb457cb7d186920f28b415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d597b6d2764e4ebec8946f0bcf7294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "635d6ced2b0747709c22c9711f528a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f8a3b092d041dda6a1efce4a54f711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}